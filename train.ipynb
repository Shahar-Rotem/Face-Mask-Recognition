{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from FaceMaskDataset import FaceMaskDataset\n",
    "from FaceMaskModel import MobileNetV3\n",
    "\n",
    "from Conv3dModel import CNN\n",
    "\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, eval_dataloaders, datasets_sizes, criterion, optimizer, device='cuda:0', num_epochs=20, print_epoch=1, scheduler=None, data_types=['train', 'test'], save_model=False):\n",
    "    start_time = time.time()\n",
    "    best_f1 = 0.0\n",
    "    best_model = deepcopy(model.state_dict())\n",
    "\n",
    "    epoch_losses = {data_type: [] for data_type in data_types}\n",
    "    epoch_aucs = {data_type: [] for data_type in data_types}\n",
    "    epoch_f1s = {data_type: [] for data_type in data_types}\n",
    "    \n",
    "    for epoch in range(0, num_epochs + 1):\n",
    "        start_epoch = time.time()\n",
    "        print(\"Epoch [{}/{}]\".format(str(epoch).zfill(len(str(num_epochs))), num_epochs))\n",
    "        \n",
    "        if epoch != 0:\n",
    "            model.train()\n",
    "\n",
    "            for _, images, labels in train_dataloader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    outputs = model(images)\n",
    "                    \n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "           \n",
    "        model.eval()\n",
    "        \n",
    "        for data_type in data_types:\n",
    "            epoch_loss = 0.0\n",
    "            \n",
    "            y_true = np.empty(0)\n",
    "            y_pred = np.empty(0)\n",
    "            y_score = np.empty(0)\n",
    "        \n",
    "            for _, images, labels in eval_dataloaders[data_type]:\n",
    "                y_true = np.append(y_true, labels.numpy())\n",
    "                \n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                                \n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = model(images)\n",
    "            \n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                    scores = F.softmax(outputs, 1)[:,1]\n",
    "                    y_score = np.append(y_score, scores.to('cpu').numpy())\n",
    "                    \n",
    "                    _, pred = torch.max(outputs, 1)\n",
    "                    y_pred = np.append(y_pred, pred.to('cpu').numpy())\n",
    "                        \n",
    "                epoch_loss += loss.item() * images.size(0)\n",
    "                \n",
    "            epoch_loss = epoch_loss / datasets_sizes[data_type]\n",
    "            epoch_acc = accuracy_score(y_true, y_pred) * 100\n",
    "            epoch_p = precision_score(y_true, y_pred, zero_division=0) * 100\n",
    "            epoch_r = recall_score(y_true, y_pred, zero_division=0) * 100\n",
    "            epoch_f1 = f1_score(y_true, y_pred, average='binary', zero_division=0) * 100\n",
    "            epoch_roc_auc = roc_auc_score(y_true, y_score) * 100\n",
    "\n",
    "            epoch_losses[data_type].append(epoch_loss)\n",
    "            epoch_aucs[data_type].append(epoch_roc_auc)\n",
    "            epoch_f1s[data_type].append(epoch_f1)\n",
    "            \n",
    "            print('{} Loss: {:.4f} F1: {:2.2f} Precision: {:2.2f} Recall: {:2.2f} Accuracy: {:2.2f} ROC-AUC: {:2.2f}'\n",
    "                    .format(data_type.ljust(5), epoch_loss, epoch_f1, epoch_p, epoch_r, epoch_acc, epoch_roc_auc))\n",
    "            \n",
    "            if data_type == 'test' and epoch_f1 > best_f1:\n",
    "                best_f1 = epoch_f1\n",
    "                best_model = deepcopy(model.state_dict())\n",
    "        \n",
    "        epoch_elapsed = time.time() - start_epoch\n",
    "        print('Epoch {} took {}m {:.0f}s'\n",
    "                .format(epoch, int(epoch_elapsed // 60), epoch_elapsed % 60))\n",
    "        \n",
    "        print('-' * 90)\n",
    "        \n",
    "    time_elapsed = time.time() - start_time\n",
    "    print('Training complete in {}m {:.0f}s'\n",
    "            .format(int(time_elapsed // 60), time_elapsed % 60))\n",
    "\n",
    "    oss_df = pd.DataFrame(epoch_losses)\n",
    "    auc_df = pd.DataFrame(epoch_aucs)\n",
    "    f1_df = pd.DataFrame(epoch_f1s)\n",
    "\n",
    "    melted_loss = pd.melt(loss_df.reset_index(), 'index').rename(columns={'index': 'Epoch', 'variable': 'Phase', 'value':'Loss'})\n",
    "    melted_auc = pd.melt(auc_df.reset_index(), 'index').rename(columns={'index': 'Epoch', 'variable': 'Phase', 'value':'AUC'})\n",
    "    melted_f1 = pd.melt(f1_df.reset_index(), 'index').rename(columns={'index': 'Epoch', 'variable': 'Phase', 'value':'F1-Score'})\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, sharex=True, figsize=(10,15))\n",
    "\n",
    "    sns.lineplot(x='Epoch', y='Loss', hue='Phase', data=melted_loss, ax=ax1).set_xticks(range(0,21))\n",
    "    sns.lineplot(x='Epoch', y='AUC', hue='Phase', data=melted_auc, ax=ax2).set_xticks(range(0,21))\n",
    "    sns.lineplot(x='Epoch', y='F1-Score', hue='Phase', data=melted_f1, ax=ax3).set_xticks(range(0,21))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print('Best test F1: {:2f}'.format(best_f1))\n",
    "    if save_model:\n",
    "        torch.save(best_model, 'model_{:2f}.pkl'.format(best_f1))\n",
    "    model.load_state_dict(best_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir='/StudentData/hw2_data'\n",
    "phases = ['train', 'eval']\n",
    "data_types = ['train', 'test']\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FaceMaskDataset(root_dir=f'{root_dir}/train', have_label=True, phase='train')\n",
    "eval_datasets = {data_type : FaceMaskDataset(root_dir=f'{root_dir}/{data_type}', have_label=True,  phase='eval') for data_type in data_types}\n",
    "\n",
    "datasets_sizes = {data_type : len(eval_datasets[data_type]) for data_type in data_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = {\n",
    "    'train' : 128,\n",
    "    'eval' : 64\n",
    "}\n",
    "\n",
    "shuffles = {\n",
    "    'train' : True,\n",
    "    'eval' : False\n",
    "}\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_sizes['train'], shuffles['train'])\n",
    "eval_dataloaders = {data_type : DataLoader(eval_datasets[data_type], batch_sizes['eval'], shuffles['eval']) for data_type in data_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV3(n_class=2, input_size=224, dropout=0.0, mode='large', width_mult=1.0)\n",
    "model = model.to(device)\n",
    "print('Total Number of Parameters: {:.2f}M'.format(sum(param.numel() for param in model.parameters()) / 1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate *= gamma every (step_size) epochs\n",
    "learning_rate = 1e-3\n",
    "step_size = 5\n",
    "gamma = 1e-1\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = train_model(model, train_dataloader, eval_dataloaders, datasets_sizes, criterion, optimizer, device=device, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), \"mask_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Parameters: 0.09M\n"
     ]
    }
   ],
   "source": [
    "model = CNN(num_class=2)\n",
    "model = model.to(device)\n",
    "print('Total Number of Parameters: {:.2f}M'.format(sum(param.numel() for param in model.parameters()) / 1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "num_epochs = 2000\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "\n",
    "# Loss and Optimizer\n",
    "# Softmax is internally computed.\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [00/20]\n",
      "train Loss: 0.6941 F1: 0.00 Precision: 0.00 Recall: 0.00 Accuracy: 45.52 ROC-AUC: 53.02\n",
      "test  Loss: 0.6940 F1: 0.00 Precision: 0.00 Recall: 0.00 Accuracy: 45.94 ROC-AUC: 53.34\n",
      "Epoch 0 took 2m 30s\n",
      "------------------------------------------------------------------------------------------\n",
      "Epoch [01/20]\n",
      "train Loss: 0.3383 F1: 91.26 Precision: 90.67 Recall: 91.85 Accuracy: 90.41 ROC-AUC: 94.62\n",
      "test  Loss: 0.3213 F1: 91.73 Precision: 91.30 Recall: 92.16 Accuracy: 91.01 ROC-AUC: 95.02\n",
      "Epoch 1 took 2m 34s\n",
      "------------------------------------------------------------------------------------------\n",
      "Epoch [02/20]\n",
      "train Loss: 0.2176 F1: 92.85 Precision: 91.53 Recall: 94.20 Accuracy: 92.09 ROC-AUC: 97.14\n",
      "test  Loss: 0.2078 F1: 93.46 Precision: 92.52 Recall: 94.41 Accuracy: 92.85 ROC-AUC: 97.35\n",
      "Epoch 2 took 2m 35s\n",
      "------------------------------------------------------------------------------------------\n",
      "Epoch [03/20]\n",
      "train Loss: 0.1922 F1: 93.54 Precision: 93.17 Recall: 93.91 Accuracy: 92.93 ROC-AUC: 97.61\n",
      "test  Loss: 0.1842 F1: 93.61 Precision: 93.43 Recall: 93.80 Accuracy: 93.08 ROC-AUC: 97.85\n",
      "Epoch 3 took 2m 34s\n",
      "------------------------------------------------------------------------------------------\n",
      "Epoch [04/20]\n"
     ]
    }
   ],
   "source": [
    "best_model = train_model(model, train_dataloader, eval_dataloaders, datasets_sizes, criterion, optimizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-face_mask",
   "language": "python",
   "name": "conda-env-.conda-face_mask-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
